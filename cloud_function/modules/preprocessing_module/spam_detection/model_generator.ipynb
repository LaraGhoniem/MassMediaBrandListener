{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.2-cp310-cp310-win_amd64.whl (10.7 MB)\n",
      "     ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/10.7 MB 1.1 MB/s eta 0:00:10\n",
      "      --------------------------------------- 0.2/10.7 MB 2.0 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.3/10.7 MB 2.4 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 0.5/10.7 MB 2.8 MB/s eta 0:00:04\n",
      "     -- ------------------------------------- 0.7/10.7 MB 3.0 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 0.8/10.7 MB 3.2 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.0/10.7 MB 3.3 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.2/10.7 MB 3.3 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.4/10.7 MB 3.4 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.6/10.7 MB 3.4 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 1.8/10.7 MB 3.5 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 1.9/10.7 MB 3.5 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/10.7 MB 3.5 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.2/10.7 MB 3.5 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.4/10.7 MB 3.4 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.5/10.7 MB 3.4 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.6/10.7 MB 3.3 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.6/10.7 MB 3.3 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.6/10.7 MB 3.3 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.6/10.7 MB 3.3 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.6/10.7 MB 2.8 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.6/10.7 MB 2.8 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 3.2/10.7 MB 3.0 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 3.5/10.7 MB 3.1 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 3.6/10.7 MB 3.2 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 3.7/10.7 MB 3.2 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 3.7/10.7 MB 3.2 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 4.1/10.7 MB 3.2 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 4.2/10.7 MB 3.2 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 4.4/10.7 MB 3.2 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 4.6/10.7 MB 3.2 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 4.8/10.7 MB 3.2 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 4.9/10.7 MB 3.2 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.0/10.7 MB 3.2 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 5.1/10.7 MB 3.2 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 5.2/10.7 MB 3.2 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 5.2/10.7 MB 3.2 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 5.4/10.7 MB 3.1 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 5.5/10.7 MB 3.1 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 5.7/10.7 MB 3.1 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 5.8/10.7 MB 3.0 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 5.9/10.7 MB 3.0 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 6.0/10.7 MB 3.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 6.1/10.7 MB 3.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 6.3/10.7 MB 3.0 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 6.4/10.7 MB 3.0 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 6.5/10.7 MB 3.0 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 6.6/10.7 MB 3.0 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 6.7/10.7 MB 3.0 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 6.9/10.7 MB 3.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 7.0/10.7 MB 3.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 7.1/10.7 MB 3.0 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 7.2/10.7 MB 2.9 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 7.3/10.7 MB 2.9 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 7.5/10.7 MB 2.9 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 7.5/10.7 MB 2.9 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 7.7/10.7 MB 2.9 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 7.8/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 8.0/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 8.1/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 8.2/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 8.4/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 8.5/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 8.6/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 8.7/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 8.9/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 9.0/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 9.2/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 9.3/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 9.4/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 9.5/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 9.6/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 9.7/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 9.8/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 9.9/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 10.0/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 10.2/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 10.3/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.5/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.6/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.6/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 10.7/10.7 MB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\omen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\omen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ---------------------------------------- 0.0/341.8 kB ? eta -:--:--\n",
      "     ---------- ---------------------------- 92.2/341.8 kB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------- --------------- 204.8/341.8 kB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- --- 307.2/341.8 kB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 341.8/341.8 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "     ---------------------------------------- 0.0/502.3 kB ? eta -:--:--\n",
      "     ------- ------------------------------- 92.2/502.3 kB 2.6 MB/s eta 0:00:01\n",
      "     ----------------- -------------------- 225.3/502.3 kB 2.8 MB/s eta 0:00:01\n",
      "     --------------------------- ---------- 368.6/502.3 kB 2.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  501.8/502.3 kB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 502.3/502.3 kB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\omen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.0.2 pytz-2023.3 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\OMEN\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('arabic')\n",
    "def preprocess(tweet):\n",
    "    # Tokenize the tweet\n",
    "    tokens = word_tokenize(tweet)\n",
    "\n",
    "    # Remove stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Join the tokens back into a single string\n",
    "    preprocessed_tweet = ' '.join(filtered_tokens)\n",
    "\n",
    "    return preprocessed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    # Remove all non-alphanumeric characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Replace all white space characters with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data_set.csv\")\n",
    "X = dataset['text']\n",
    "labels = dataset['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting display\n",
      "  Downloading display-1.0.0.tar.gz (687 bytes)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Installing collected packages: display\n",
      "  Running setup.py install for display: started\n",
      "  Running setup.py install for display: finished with status 'done'\n",
      "Successfully installed display-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: display is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\OMEN\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>اعترف ان بتس كانو شوي شوي يجيبو راسي لكن اليوم...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>توقعت اذا جات داريا بشوفهم كاملين بس لي للحين ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>#الاهلي_الهلال اكتب توقعك لنتيجة لقاء الهلال و...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>نعمة المضادات الحيوية . تضع قطرة💧مضاد بنسلين ع...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>الدودو جايه تكمل علي 💔</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45269</th>\n",
       "      <td>pos</td>\n",
       "      <td>السحب الليلة على الايفون .. رتويت للمرفقة وطبق...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45270</th>\n",
       "      <td>pos</td>\n",
       "      <td>😂 لابسة احمر ليه يا ست انتي ايه المناسبة 😂</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45271</th>\n",
       "      <td>pos</td>\n",
       "      <td>كلاام جمييل تستاهل(من احبه الله جعل محبته ف قل...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45272</th>\n",
       "      <td>pos</td>\n",
       "      <td>- ألطف صورة ممكن تعبر عن رمضان 💙</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45273</th>\n",
       "      <td>pos</td>\n",
       "      <td>🌸 قال #الإمام_ابن_القيم -رحمه الله تعالى- : - ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45274 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                               text Unnamed: 2  \\\n",
       "0       neg  اعترف ان بتس كانو شوي شوي يجيبو راسي لكن اليوم...        NaN   \n",
       "1       neg  توقعت اذا جات داريا بشوفهم كاملين بس لي للحين ...        NaN   \n",
       "2       neg  #الاهلي_الهلال اكتب توقعك لنتيجة لقاء الهلال و...        NaN   \n",
       "3       neg  نعمة المضادات الحيوية . تضع قطرة💧مضاد بنسلين ع...        NaN   \n",
       "4       neg                             الدودو جايه تكمل علي 💔        NaN   \n",
       "...     ...                                                ...        ...   \n",
       "45269   pos  السحب الليلة على الايفون .. رتويت للمرفقة وطبق...        NaN   \n",
       "45270   pos         😂 لابسة احمر ليه يا ست انتي ايه المناسبة 😂        NaN   \n",
       "45271   pos  كلاام جمييل تستاهل(من احبه الله جعل محبته ف قل...        NaN   \n",
       "45272   pos                   - ألطف صورة ممكن تعبر عن رمضان 💙        NaN   \n",
       "45273   pos  🌸 قال #الإمام_ابن_القيم -رحمه الله تعالى- : - ...        NaN   \n",
       "\n",
       "      Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8  \\\n",
       "0            NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1            NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2            NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3            NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4            NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "45269        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "45270        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "45271        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "45272        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "45273        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "      Unnamed: 9 Unnamed: 10  \n",
       "0            NaN         NaN  \n",
       "1            NaN         NaN  \n",
       "2            NaN         NaN  \n",
       "3            NaN         NaN  \n",
       "4            NaN         NaN  \n",
       "...          ...         ...  \n",
       "45269        NaN         NaN  \n",
       "45270        NaN         NaN  \n",
       "45271        NaN         NaN  \n",
       "45272        NaN         NaN  \n",
       "45273        NaN         NaN  \n",
       "\n",
       "[45274 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a label encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Encode the labels\n",
    "labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_tweets = X.str.replace(r'#\\S+', '', regex=True)\n",
    "preprocessed_tweets = X.str.replace(r'@\\S+', '', regex=True)\n",
    "preprocessed_tweets = X.str.replace(r'http\\S+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_tweets = [preprocess(tweet) for tweet in preprocessed_tweets]\n",
    "preprocessed_tweets = [remove_emojis(tweet) for tweet in preprocessed_tweets]\n",
    "preprocessed_tweets = [remove_special_characters(tweet) for tweet in preprocessed_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_tweets, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.8, sublinear_tf=True)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel=\"rbf\")\n",
    "# clf = LinearRegression()\n",
    "clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.05872332 0.77342695 0.91674619 ... 0.91674619 0.13255873 0.99937206]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lara\\Documents\\GitHub\\MassMediaBrandListener\\modules\\preprocessing_module\\spam_detection\\model_generator.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lara/Documents/GitHub/MassMediaBrandListener/modules/preprocessing_module/spam_detection/model_generator.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(y_pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lara/Documents/GitHub/MassMediaBrandListener/modules/preprocessing_module/spam_detection/model_generator.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Calculate the accuracy, precision, and recall\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lara/Documents/GitHub/MassMediaBrandListener/modules/preprocessing_module/spam_detection/model_generator.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lara/Documents/GitHub/MassMediaBrandListener/modules/preprocessing_module/spam_detection/model_generator.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# precision = precision_score(y_test, y_pred)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lara/Documents/GitHub/MassMediaBrandListener/modules/preprocessing_module/spam_detection/model_generator.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# recall = recall_score(y_test, y_pred)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lara/Documents/GitHub/MassMediaBrandListener/modules/preprocessing_module/spam_detection/model_generator.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy:\u001b[39m\u001b[39m\"\u001b[39m, accuracy)\n",
      "File \u001b[1;32mc:\\Users\\Lara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Lara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Calculate the accuracy, precision, and recall\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# precision = precision_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# print(\"Precision:\", precision)\n",
    "# print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "كود خصم ايهرب 10 % 😍😍😍😍😍😍 . CDW0635 # الهلال_نيوكاسل # كود_خصم # اكواد # iherb # عنايه # Discounts # skincare # جده_lلان # حساب_الموطن # كرواتيا_الارجنتين # المغرب_فرنسا # where_is_Messi # الارجنتين_فرنسا # WorldCup # Messi𓃵 # WorldCupFinal # chainsawman # JENLISA # جديد_المجد\n",
      "  (0, 1)\t1.0\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"كود خصم ايهرب 10%😍😍😍😍😍😍.                CDW0635\\n#الهلال_نيوكاسل #كود_خصم #اكواد #iherb #عنايه #Discounts #skincare #جده_lلان #حساب_الموطن #كرواتيا_الارجنتين #المغرب_فرنسا #where_is_Messi #الارجنتين_فرنسا #WorldCup #Messi𓃵 #WorldCupFinal #chainsawman #JENLISA #جديد_المجد\"\n",
    "text = preprocess(text)\n",
    "print(text)\n",
    "X_train_tfidf = vectorizer.transform([text])\n",
    "print(X_train_tfidf)\n",
    "y_pred = clf.predict(X_train_tfidf)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"tweet_spam_filter_arabic.pkl\",\"wb\") as f:\n",
    "    pickle.dump(clf,f)\n",
    "with open(\"tweet_spam_vectorizer_arabic.pkl\",\"wb\") as f:\n",
    "    pickle.dump(vectorizer,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "vectorizer = None\n",
    "with open('tweet_spam_filter_arabic.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "with open('tweet_spam_vectorizer_arabic.pkl', 'rb') as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "text = \"كود خصم ايهرب 10%😍😍😍😍😍😍.CDW0635\\n#الهلال_نيوكاسل #كود_خصم #اكواد #iherb #عنايه #Discounts #skincare #جده_lلان #حساب_الموطن #كرواتيا_الارجنتين #المغرب_فرنسا #where_is_Messi #الارجنتين_فرنسا #WorldCup #Messi𓃵 #WorldCupFinal #chainsawman #JENLISA #جديد_المجد\"\n",
    "text = preprocess(text)\n",
    "X_train_tfidf = vectorizer.transform([text])\n",
    "y_pred = model.predict(X_train_tfidf)\n",
    "print(y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f324bbd7cdb8d90cc3e0ade5a166b9b8d5ce30d1926a40871048070cc4d10367"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
